{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamoye ML Project Electric Cars - Team Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scrapped from Web - by Team 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (1.25.9)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import selenium\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scrapping of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'webdriver_manager'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3d71999261aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwebdriver_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchrome\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChromeDriverManager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchrome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'webdriver_manager'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "car_name = []\n",
    "car_model = []\n",
    "car_battery = []\n",
    "car_seats = []\n",
    "car_acceleration = []\n",
    "car_speed = []\n",
    "car_distance = []\n",
    "car_eff = []\n",
    "car_charge = []\n",
    "price_g = []\n",
    "price_n = []\n",
    "price_p = []\n",
    "\n",
    "\n",
    "option = Options()\n",
    "option.headless = True\n",
    "browser = webdriver.Chrome(ChromeDriverManager().install())\n",
    "url = 'https://ev-database.org/'\n",
    "browser.get(url)\n",
    "time.sleep(10)\n",
    "browser.find_element_by_xpath('//div[@id=\"paging\"]').click()\n",
    "browser.find_element_by_xpath('//*[@id=\"paging\"]/ul/li[4]').click()\n",
    "time.sleep(20)\n",
    "car_list = browser.find_elements_by_xpath('//div[@class=\"data-wrapper\"]')\n",
    "for names in car_list:\n",
    "    name = names.find_element_by_xpath('.//a[@class=\"title\"]/span').text\n",
    "    car_name.append(name)\n",
    "    model = names.find_element_by_xpath('.//a[@class=\"title\"]/span[2]').text\n",
    "    car_model.append(model)\n",
    "    battery = names.find_element_by_xpath('.//div[@class=\"subtitle\"]/span').text.split(' ')[0]\n",
    "    car_battery.append(battery)\n",
    "    seats = names.find_element_by_xpath('.//div[@class=\"icons\"]/span[6]').text\n",
    "    car_seats.append(seats)\n",
    "    acceleration = names.find_element_by_xpath('.//div[@class=\"specs\"]/p/span[2]').text.split(' ')[0]\n",
    "    car_acceleration.append(acceleration)\n",
    "    speed = names.find_element_by_xpath('.//div[@class=\"specs\"]/p[2]/span[2]').text.split(' ')[0]\n",
    "    car_speed.append(speed)\n",
    "    distance = names.find_element_by_xpath('.//div[@class=\"specs\"]/p[3]/span[2]').text.split(' ')[0]\n",
    "    car_distance.append(distance)\n",
    "    efficiency = names.find_element_by_xpath('.//div[@class=\"specs\"]/p[4]/span[2]').text.split(' ')[0]\n",
    "    car_eff.append(efficiency)\n",
    "    fast_charge = names.find_element_by_xpath('.//div[@class=\"specs\"]/p[5]/span[2]').text.split(' ')[0]\n",
    "    car_charge.append(fast_charge)\n",
    "    price_gbp = names.find_element_by_xpath('.//div[@class=\"pricing align-right\"]/span[3]').text[1:]\n",
    "    price_p.append(price_gbp)\n",
    "    price_germany = names.find_element_by_xpath('.//div[@class=\"pricing align-right\"]/span[1]').text[1:]\n",
    "    price_g.append(price_germany)\n",
    "    price_netherland = names.find_element_by_xpath('.//div[@class=\"pricing align-right\"]/span[2]').text[1:]\n",
    "    price_n.append(price_netherland)\n",
    "\n",
    "# saving the data into a dictionary and then turning it into a csv file\n",
    "car_data = {'vehicle_name':car_name,'model':car_model,'battery':car_battery,'seats':car_seats,\n",
    "            'acceleration':car_acceleration,'top_speed':car_speed,'distance':car_distance,'efficiency':car_eff,\n",
    "            'fast_charge':car_charge,'price_pounds':price_p,'price_germany':price_g,'price_netherland':price_n}\n",
    "# print(car_data)\n",
    "car_df = pd.DataFrame().from_dict(car_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataframe\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe to CSV file, for later quick reference\n",
    "car_df.to_csv('D:\\People\\Amit\\Hamoye\\project\\\\electric_cars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Treatment by Team 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read/Load the dataset from local CSV file\n",
    "# Writing index_col=0 doesn't add additional column 'Unnamed: 0', while importing data from CSV File\n",
    "df = pd.read_csv('D:\\People\\Amit\\Hamoye\\project\\\\electric_cars.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data-types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, apart from vehicle_name and model all other columns should be numeric, lets convert them to Numeric types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'fast_charge': np.int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe that fast-charge is not converting to int type because of string value '-'\n",
    "#### Let us find and replace it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find '-' in dataset\n",
    "df[df.isin(['-'])].stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Its present only in fast-charge column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace string '-' with Null Value\n",
    "df['fast_charge']=df['fast_charge'].replace(to_replace='-', value=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Null values\n",
    "df['fast_charge'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Null values with Median values\n",
    "df['fast_charge'] = df['fast_charge'].fillna(df['fast_charge'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-check Null values\n",
    "df['fast_charge'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert fast-charge to Numeric type \n",
    "df = df.astype({'fast_charge': np.int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data-types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us convert price_pounds, price_germany and price_netherland to Numeric types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'price_pounds': np.int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Its not getting converted, we need to clean it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning comma(,), curency symbols(£,€), and replacing N/A(/A) values with Null(NaN).\n",
    "df['price_pounds'] = df['price_pounds'].str.replace(',', '')\n",
    "df['price_pounds'] = df['price_pounds'].str.replace('£', '')\n",
    "df['price_pounds'] = df['price_pounds'].str.replace('€', '')\n",
    "df['price_pounds'] = df['price_pounds'].str.replace('/A', '')\n",
    "df['price_pounds'] = df['price_pounds'].replace(to_replace='', value=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check its Null values\n",
    "df['price_pounds'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check its dtype\n",
    "df['price_pounds'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert it into numeric type\n",
    "df = df.astype({'price_pounds': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check its dtype again\n",
    "df['price_pounds'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we do similar cleaning for price_germany and price_netherland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning comma(,), curency symbols(£,€), and replacing N/A(/A) values with Null(NaN).\n",
    "df['price_germany'] = df['price_germany'].str.replace(',', '')\n",
    "df['price_germany'] = df['price_germany'].str.replace('£', '')\n",
    "df['price_germany'] = df['price_germany'].str.replace('€', '')\n",
    "df['price_germany'] = df['price_germany'].str.replace('/A', '')\n",
    "df['price_germany'] = df['price_germany'].replace(to_replace='', value=np.NaN)\n",
    "#Converting it to Numric data-type\n",
    "df = df.astype({'price_germany': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning comma(,), curency symbols(£,€), and replacing N/A(/A) values with Null(NaN).\n",
    "df['price_netherland'] = df['price_netherland'].str.replace(',', '')\n",
    "df['price_netherland'] = df['price_netherland'].str.replace('£', '')\n",
    "df['price_netherland'] = df['price_netherland'].str.replace('€', '')\n",
    "df['price_netherland'] = df['price_netherland'].str.replace('/A', '')\n",
    "df['price_netherland'] = df['price_netherland'].replace(to_replace='', value=np.NaN)\n",
    "#Converting it to Numric data-type\n",
    "df = df.astype({'price_netherland': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check overall data-type\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The three price columns have Null values, and price_germany has least Null Values. It is suggested that instead of keeping prices in three different currencies, we can convert the price to universal currency USD value. But before that we will see it price_germany has any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the price_germany using box-plot to visualize Outliers\n",
    "sns.boxplot(x='price_germany',data=df,orient='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We observe many outliers on the upper side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how to get the outliers\n",
    "Q1 = df['price_germany'].quantile(0.25) #First Quantile\n",
    "Q3 = df['price_germany'].quantile(0.75) # Third Quantile\n",
    "IQR = Q3 - Q1 #Interquantile Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upper side Outliers are Q3+1.5(IQR)\n",
    "#### Lower side Outliers are Q1-1.5(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## storing index locations of upper and lower outliers\n",
    "index_upper = df[df['price_germany'] >= (Q3+1.5*IQR)].index\n",
    "index_lower = df[df['price_germany'] <= (Q1-1.5*IQR)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check upper outliers\n",
    "df.iloc[index_upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check lower outlier\n",
    "df.iloc[index_lower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[index_upper].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We have 16 Outliers on Upper side. Dropping outliers from price_germanythem using below code\n",
    "df.drop(index_upper, inplace=True)\n",
    "df.drop(index_lower, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the Null values with Median values.\n",
    "df['price_germany'] = df['price_germany'].fillna(df['price_germany'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check datset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now we use price_germany to get prices in USD\n",
    "df['price_usd'] = round((df['price_germany']/1.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check Null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to get some insights from the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 5 Car Brands as per Average values of their Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 Car Brands as per Average values of their EV Car Models\n",
    "df.groupby('vehicle_name')['price_usd'].mean().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('vehicle_name')['price_usd'].mean().sort_values(ascending=False).head(5).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Car Brands with maximum no. of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Top 5 Car Brands with maximum no. of Models\n",
    "df['vehicle_name'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_name'].value_counts().head(5).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Car Models with Highest Top Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['vehicle_name','model','top_speed']]\n",
    "df1.sort_values('top_speed',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 Cars with highest Battery back-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['vehicle_name','model','battery']]\n",
    "df2.sort_values('battery',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of Car prices across the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['price_usd'],kde=False,bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation among various Features in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = df[['battery', 'seats', 'acceleration', 'top_speed', 'distance', 'efficiency', 'fast_charge', 'price_usd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = features1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see very High correlation between Distance and Battery(0.87). Also, good correlation between Fast-charge and Top speed(0.74).  Also target variable price_usd has a moderate correlation with battery(0.67)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...To be Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Unique names in vehicle_names\n",
    "df['vehicle_name'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual Encoding of Values\n",
    "cleanup_names = {\"vehicle_name\" : {'Aiways':1, 'Audi':2, 'BMW':3, 'Byton':4, 'CUPRA':5, 'Citroen':6, 'DS':7,\n",
    "      'Dacia':8, 'Fiat':9, 'Ford':10, 'Honda':11, 'Hyundai':12, 'JAC':13, 'Jaguar':14,\n",
    "       'Kia':15, 'Lexus':16, 'Lucid':17, 'MG':18, 'Mazda':19, 'Mercedes':20, 'Mini':21,\n",
    "       'Nissan':22, 'Opel':23, 'Peugeot':24, 'Polestar':25, 'Porsche':26, 'Renault':27,\n",
    "       'SEAT':28, 'Seres':29, 'Skoda':30, 'Smart':31, 'Sono':32, 'Tesla':33, 'Toyota':34,\n",
    "       'Volkswagen':35, 'Volvo':36}\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(cleanup_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALternate Method Oridnal Encoding using Scikit\n",
    "#from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "#ord_enc = OrdinalEncoder()\n",
    "#df['vehicle_name_code'] = ord_enc.fit_transform(df[['vehicle_name']])\n",
    "#df[['vehicle_name_code', 'vehicle_name']].head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('vehicle_name_code',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_name'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check dtypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['vehicle_name', 'battery', 'seats', 'acceleration',\n",
    "       'top_speed', 'distance', 'efficiency', 'fast_charge']]\n",
    "y = df['price_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data using MinMax Scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Regression\n",
    "# Import Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "#fit the model to the training dataset\n",
    "linear_model.fit(x_train, y_train)\n",
    "#obtain predictions\n",
    "pred_1 = linear_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Metrics for evaluation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error (MAE)', metrics.mean_absolute_error(y_test,pred_1))\n",
    "print('Mean Square Error (MSE)', metrics.mean_squared_error(y_test,pred_1))\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_1)))\n",
    "print('R2 score', metrics.r2_score(y_test,pred_1))\n",
    "print('Explained Variance score', metrics.explained_variance_score(y_test,pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Ridge Regression with Alpha = 0.5\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge(alpha=0.5)\n",
    "ridge_reg.fit(x_train, y_train)\n",
    "pred_2 = ridge_reg.predict(x_test)           # Use this model to predict the test data\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_2))) #RMSE\n",
    "print('R2 score', metrics.r2_score(y_test,pred_2)) #R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg_2 = Ridge(alpha=2)\n",
    "ridge_reg_2.fit(x_train, y_train)\n",
    "pred_3 = ridge_reg_2.predict(x_test)           # Use this model to predict the test data\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_3))) #RMSE\n",
    "print('R2 score', metrics.r2_score(y_test,pred_3)) #R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg_4 = Ridge(alpha=4)\n",
    "ridge_reg_4.fit(x_train, y_train)\n",
    "pred_4 = ridge_reg_4.predict(x_test)           # Use this model to predict the test data\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_4))) #RMSE\n",
    "print('R2 score', metrics.r2_score(y_test,pred_4)) #R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random FOrest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfc = RandomForestRegressor(n_estimators=300)\n",
    "rfc.fit(x_train,y_train)\n",
    "pred_5 = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_5))) #RMSE\n",
    "print('R2 score', metrics.r2_score(y_test,pred_5)) #R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xgboost Model\n",
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "xgb.fit(x_train,y_train)\n",
    "pred_6 = xgb.predict(x_test)\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_6))) #RMSE\n",
    "print('R2 score', metrics.r2_score(y_test,pred_6)) #R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying without removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\\\People\\\\Amit\\\\Hamoye\\\\project\\\\electric_cars_with-outlier.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['fast_charge'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['fast_charge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['price_germany'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now we use price_germany to get prices in USD\n",
    "df['price_usd'] = round((df['price_germany']/1.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALternate Method Oridnal Encoding using Scikit\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "df['vehicle_name_code'] = ord_enc.fit_transform(df[['vehicle_name']])\n",
    "df[['vehicle_name_code', 'vehicle_name']].head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_name_code'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_name'].sort_values().nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_name'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vehicle_name_code'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['vehicle_name_code', 'battery', 'seats', 'acceleration',\n",
    "       'top_speed', 'distance', 'efficiency', 'fast_charge']]\n",
    "y = df['price_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data using MinMax Scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Regression\n",
    "# Import Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "#fit the model to the training dataset\n",
    "linear_model.fit(x_train, y_train)\n",
    "#obtain predictions\n",
    "pred_1 = linear_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Metrics for evaluation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error (MAE)', metrics.mean_absolute_error(y_test,pred_1))\n",
    "print('Mean Square Error (MSE)', metrics.mean_squared_error(y_test,pred_1))\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_1)))\n",
    "print('R2 score', metrics.r2_score(y_test,pred_1))\n",
    "print('Explained Variance score', metrics.explained_variance_score(y_test,pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the price_germany using box-plot to visualize Outliers\n",
    "sns.boxplot(x='price_germany',data=df,orient='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random FOrest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfc = RandomForestRegressor(n_estimators=300)\n",
    "rfc.fit(x_train,y_train)\n",
    "pred_5 = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error (MAE)', metrics.mean_absolute_error(y_test,pred_5))\n",
    "print('Mean Square Error (MSE)', metrics.mean_squared_error(y_test,pred_5))\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_5))) #RMSE\n",
    "print('R2 score', metrics.r2_score(y_test,pred_5)) #R2 Score\n",
    "print('Explained Variance score', metrics.explained_variance_score(y_test,pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xgboost Model\n",
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "xgb.fit(x_train,y_train)\n",
    "pred_6 = xgb.predict(x_test)\n",
    "print('Mean Absolute Error (MAE)', metrics.mean_absolute_error(y_test,pred_6))\n",
    "print('Mean Square Error (MSE)', metrics.mean_squared_error(y_test,pred_6))\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_6))) #RMSE\n",
    "print('R2 score', metrics.r2_score(y_test,pred_6)) #R2 Score\n",
    "print('Explained Variance score', metrics.explained_variance_score(y_test,pred_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\\\People\\\\Amit\\\\Hamoye\\\\project\\\\electric_cars_with-outlier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['fast_charge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['price_germany'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now we use price_germany to get prices in USD\n",
    "df['price_usd'] = round((df['price_germany']/1.18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['battery', 'seats', 'acceleration',\n",
    "       'top_speed', 'distance', 'efficiency', 'fast_charge']]\n",
    "y = df['price_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data using MinMax Scaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Regression\n",
    "# Import Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "#fit the model to the training dataset\n",
    "linear_model.fit(x_train, y_train)\n",
    "#obtain predictions\n",
    "pred_1 = linear_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Metrics for evaluation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error (MAE)', metrics.mean_absolute_error(y_test,pred_1))\n",
    "print('Mean Square Error (MSE)', metrics.mean_squared_error(y_test,pred_1))\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_1)))\n",
    "print('R2 score', metrics.r2_score(y_test,pred_1))\n",
    "print('Explained Variance score', metrics.explained_variance_score(y_test,pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfc = RandomForestRegressor(n_estimators=300)\n",
    "rfc.fit(x_train,y_train)\n",
    "pred_2 = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error (MAE)', metrics.mean_absolute_error(y_test,pred_2))\n",
    "print('Mean Square Error (MSE)', metrics.mean_squared_error(y_test,pred_2))\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_2)))\n",
    "print('R2 score', metrics.r2_score(y_test,pred_2))\n",
    "print('Explained Variance score', metrics.explained_variance_score(y_test,pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xgboost Model\n",
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "xgb.fit(x_train,y_train)\n",
    "pred_6 = xgb.predict(x_test)\n",
    "print('Mean Absolute Error (MAE)', metrics.mean_absolute_error(y_test,pred_6))\n",
    "print('Mean Square Error (MSE)', metrics.mean_squared_error(y_test,pred_6))\n",
    "print('Root Mean Square Error (RMSE)', np.sqrt(metrics.mean_squared_error(y_test,pred_6))) #RMSE\n",
    "print('R2 score', metrics.r2_score(y_test,pred_6)) #R2 Score\n",
    "print('Explained Variance score', metrics.explained_variance_score(y_test,pred_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl= pickle.dumps(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
