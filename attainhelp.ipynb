{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-10T22:35:27.159634Z","iopub.execute_input":"2023-08-10T22:35:27.160973Z","iopub.status.idle":"2023-08-10T22:35:27.171764Z","shell.execute_reply.started":"2023-08-10T22:35:27.160905Z","shell.execute_reply":"2023-08-10T22:35:27.170549Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/attaindb/dbo-employee_type_pay_type-210-live.1690705553.csv\n/kaggle/input/attaindb/dbo-message_template-196-live.1690709451.csv\n/kaggle/input/attaindb/dbo-employee_payroll_status-245-live.1690705214.csv\n/kaggle/input/attaindb/dbo-candidate_job_application-175-live.1690703569.csv\n/kaggle/input/attaindb/dbo-payments-181-live.1690885843.csv\n/kaggle/input/attaindb/dbo-employee_job_assignment-98-live.1690704827.csv\n/kaggle/input/attaindb/dbo-ep_review_type-268-live.1690705782.csv\n/kaggle/input/attaindb/dbo-leave_request-110-live.1690709248.csv\n/kaggle/input/attaindb/dbo-shift-205-live.1690886426.csv\n/kaggle/input/attaindb/dbo-employee_change_log-247-live.1690704702.csv\n/kaggle/input/attaindb/dbo-job_offer_candidate_assignment-179-live.1690708421.csv\n/kaggle/input/attaindb/dbo-user_onboarding_task-184-live.1690887111.csv\n/kaggle/input/attaindb/dbo-employee_review_actions-264-live.1690705333.csv\n/kaggle/input/attaindb/dbo-employee_offboarding_plan-154-live.1690705138.csv\n/kaggle/input/attaindb/dbo-approval_request-189-live.1690703407.csv\n/kaggle/input/attaindb/dbo-attendance-203-live.1690703457.csv\n/kaggle/input/attaindb/dbo-review_action-261-live.1690886153.csv\n/kaggle/input/attaindb/dbo-ep_employee_review_response-271-live.1690705646.csv\n/kaggle/input/attaindb/dbo-record_status-94-live.1690886102.csv\n/kaggle/input/attaindb/dbo-public_holiday-238-live.1690886061.csv\n/kaggle/input/attaindb/dbo-review_template-251-live.1690886273.csv\n/kaggle/input/attaindb/dbo-goal-254-live.1690707711.csv\n/kaggle/input/attaindb/dbo-employee_paytypes-218-live.1690705274.csv\n/kaggle/input/attaindb/dbo-onboarding_progress-185-live.1690885653.csv\n/kaggle/input/attaindb/dbo-job_history-278-live.1690708031.csv\n/kaggle/input/attaindb/dbo-organization-123-live.1690885664.csv\n/kaggle/input/attaindb/dbo-contract_history-138-live.1690704945.csv\n/kaggle/input/attaindb/dbo-candidate_history-276-live.1690703533.csv\n/kaggle/input/attaindb/dbo-ep_employee_review-263-live.1690705608.csv\n/kaggle/input/attaindb/dbo-contract-101-live.1690704906.csv\n/kaggle/input/attaindb/dbo-transaction_types-91-live.1690886734.csv\n/kaggle/input/attaindb/dbo-notification2-199-live.1690709492.csv\n/kaggle/input/attaindb/dbo-employee_history-87-live.1690704805.csv\n/kaggle/input/attaindb/dbo-leave_balance-109-live.1690709144.csv\n/kaggle/input/attaindb/dbo-employee_pay_schedule-225-live.1690705186.csv\n/kaggle/input/attaindb/dbo-employee_leave_type_assignment-173-live.1690705089.csv\n/kaggle/input/attaindb/dbo-candidate_interview_assignment-177-live.1690703547.csv\n/kaggle/input/attaindb/dbo-job_job_board-258-live.1690708086.csv\n/kaggle/input/attaindb/app_subscription.csv\n/kaggle/input/attaindb/dbo-manager_assignment-151-live.1690709411.csv\n/kaggle/input/attaindb/dbo-contract_template-102-live.1690705056.csv\n/kaggle/input/attaindb/dbo-job_offer_template-180-live.1690708972.csv\n/kaggle/input/attaindb/dbo-pay_schedule-226-live.1690885789.csv\n/kaggle/input/attaindb/dbo-job-97-live.1690707945.csv\n/kaggle/input/attaindb/dbo-role-147-live.1690886345.csv\n/kaggle/input/attaindb/dbo-employee_schedule-204-live.1690705353.csv\n/kaggle/input/attaindb/dbo-currency-241-live.1690703615.csv\n/kaggle/input/attaindb/dbo-user_roles-121-live.1690887165.csv\n/kaggle/input/attaindb/dbo-job_change_log-279-live.1690707979.csv\n/kaggle/input/attaindb/dbo-job_grade_asnmt-128-live.1690707999.csv\n/kaggle/input/attaindb/dbo-ep_review_cycle-250-live.1690705704.csv\n/kaggle/input/attaindb/dbo-employee-83-live.1690704648.csv\n/kaggle/input/attaindb/dbo-expired_contract-145-live.1690705813.csv\n/kaggle/input/attaindb/dbo-employee_type-89-live.1690705512.csv\n/kaggle/input/attaindb/dbo-candidate-174-live.1690703493.csv\n/kaggle/input/attaindb/dbo-hiring_stage-169-live.1690707816.csv\n/kaggle/input/attaindb/dbo-leave_type-106-live.1690709330.csv\n/kaggle/input/attaindb/dbo-approval_type-150-live.1690703434.csv\n/kaggle/input/attaindb/dbo-candidate_change_log-272-live.1690703512.csv\n/kaggle/input/attaindb/dbo-user_profile-182-live.1690887141.csv\n/kaggle/input/attaindb/dbo-payroll_config-237-live.1690885884.csv\n/kaggle/input/attaindb/dbo-ep_review-269-live.1690705685.csv\n/kaggle/input/attaindb/dbo-ep_review_question-270-live.1690705733.csv\n/kaggle/input/attaindb/dbo-employee_schedule-204-live.1690705456.csv\n/kaggle/input/attaindb/dbo-employee_department_asnmt-135-live.1690704742.csv\n/kaggle/input/attaindb/dbo-user-118-live.1690886907.csv\n/kaggle/input/attaindb/dbo-department-112-live.1690704597.csv\n/kaggle/input/attaindb/dbo-country-239-live.1690703594.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\nfrom transformers import TapasConfig, TapasForQuestionAnswering, AdamW\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:35:32.520335Z","iopub.execute_input":"2023-08-10T22:35:32.521505Z","iopub.status.idle":"2023-08-10T22:35:38.447770Z","shell.execute_reply.started":"2023-08-10T22:35:32.521463Z","shell.execute_reply":"2023-08-10T22:35:38.446388Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.8/site-packages (4.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from transformers) (6.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from transformers) (23.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.8/site-packages (from transformers) (0.3.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.8/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (1.26.16)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests->transformers) (3.2.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"table=pd.read_csv(\"/kaggle/input/attaindb/dbo-user_roles-121-live.1690887165.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:36:13.255613Z","iopub.execute_input":"2023-08-10T22:36:13.256642Z","iopub.status.idle":"2023-08-10T22:36:13.268736Z","shell.execute_reply.started":"2023-08-10T22:36:13.256595Z","shell.execute_reply":"2023-08-10T22:36:13.267800Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"table.head(20)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:36:15.777946Z","iopub.execute_input":"2023-08-10T22:36:15.779290Z","iopub.status.idle":"2023-08-10T22:36:15.805737Z","shell.execute_reply.started":"2023-08-10T22:36:15.779249Z","shell.execute_reply":"2023-08-10T22:36:15.804608Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"    id     created_at  updated_at  role_id  user_id  organization_id\n0    1  1678188102403         NaN      2.0      2.0                1\n1    2  1678188748408         NaN      2.0      1.0                1\n2    3  1678364291689         NaN      4.0      3.0                1\n3    4  1679577582879         NaN      4.0      2.0                1\n4    5  1683981876930         NaN      6.0      2.0                1\n5    6  1683982999742         NaN      1.0      1.0                1\n6    7  1683989517132         NaN      8.0      2.0                1\n7   11  1683996515849         NaN      7.0      2.0                1\n8   13  1684002096221         NaN      5.0      2.0                1\n9   14  1684002898164         NaN      8.0      1.0                1\n10  15  1685473571520         NaN      1.0      1.0                1\n11  16  1686380850101         NaN      1.0     40.0                1\n12  17  1686413731718         NaN      1.0      2.0                1\n13  18  1686413740399         NaN      NaN      NaN                0\n14  19  1687349905340         NaN      1.0     39.0                1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>created_at</th>\n      <th>updated_at</th>\n      <th>role_id</th>\n      <th>user_id</th>\n      <th>organization_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1678188102403</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1678188748408</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1678364291689</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1679577582879</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1683981876930</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>1683982999742</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>1683989517132</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>11</td>\n      <td>1683996515849</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>13</td>\n      <td>1684002096221</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>14</td>\n      <td>1684002898164</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>15</td>\n      <td>1685473571520</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>16</td>\n      <td>1686380850101</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>40.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>17</td>\n      <td>1686413731718</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>18</td>\n      <td>1686413740399</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>19</td>\n      <td>1687349905340</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>39.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TapasTokenizer\n\n# Load the TapasTokenizer\ntokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base\")","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:36:20.274541Z","iopub.execute_input":"2023-08-10T22:36:20.275067Z","iopub.status.idle":"2023-08-10T22:36:21.038231Z","shell.execute_reply.started":"2023-08-10T22:36:20.275029Z","shell.execute_reply":"2023-08-10T22:36:21.037303Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Downloading (…)solve/main/vocab.txt: 100%|██████████| 262k/262k [00:00<00:00, 4.61MB/s]\nDownloading (…)cial_tokens_map.json: 100%|██████████| 154/154 [00:00<00:00, 18.6kB/s]\nDownloading (…)okenizer_config.json: 100%|██████████| 490/490 [00:00<00:00, 274kB/s]\nDownloading (…)lve/main/config.json: 100%|██████████| 1.52k/1.52k [00:00<00:00, 841kB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generate a list of questions for each column and row combination\nquestions = []\nfor col in table.columns:\n    for i, row in table.iterrows():\n        questions.append(f\"What is the value in the {col} column for row {i + 1}?\")\n\n# Generate corresponding answer coordinates and answer text\nanswer_coordinates = [[(i, col_idx)] for col_idx in range(len(table.columns)) for i in range(len(table))]\nanswer_text = [str(table.iat[i, col_idx]) for col_idx in range(len(table.columns)) for i in range(len(table))]\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:36:31.726336Z","iopub.execute_input":"2023-08-10T22:36:31.726724Z","iopub.status.idle":"2023-08-10T22:36:31.742651Z","shell.execute_reply.started":"2023-08-10T22:36:31.726693Z","shell.execute_reply":"2023-08-10T22:36:31.741659Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Tokenize the data\ninputs = tokenizer(\n    table=table.astype(str),  # Convert table data to text-only\n    queries=questions,\n    answer_coordinates=answer_coordinates,\n    answer_text=answer_text,\n    padding=\"max_length\",\n    return_tensors=\"pt\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:36:40.977506Z","iopub.execute_input":"2023-08-10T22:36:40.978359Z","iopub.status.idle":"2023-08-10T22:36:46.172837Z","shell.execute_reply.started":"2023-08-10T22:36:40.978318Z","shell.execute_reply":"2023-08-10T22:36:46.171970Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass TableDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, tokenizer):\n        self.inputs = inputs\n        self.tokenizer = tokenizer\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.inputs.items()}\n        return item\n\n    def __len__(self):\n        return len(self.inputs[\"input_ids\"])\n\n# Create the DataLoader\ntrain_dataset = TableDataset(inputs, tokenizer)\nbatch_size = 8  # You can adjust this based on your resources\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:36:51.270984Z","iopub.execute_input":"2023-08-10T22:36:51.271901Z","iopub.status.idle":"2023-08-10T22:36:51.280449Z","shell.execute_reply.started":"2023-08-10T22:36:51.271867Z","shell.execute_reply":"2023-08-10T22:36:51.279418Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import TapasConfig, TapasForQuestionAnswering, AdamW\n\n# Define the configuration\nconfig = TapasConfig(\n    num_aggregation_labels=4,\n    use_answer_as_supervision=True,\n    answer_loss_cutoff=0.664694,\n    cell_selection_preference=0.207951,\n    huber_loss_delta=0.121194,\n    init_cell_selection_weights_to_zero=True,\n    select_one_column=True,\n    allow_empty_column_selection=False,\n    temperature=0.0352513,\n    \n)\n\n# Initialize the model\nmodel = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n\n# Set up optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# Put the model in training mode\nmodel.train()\n\n# Training loop\nepochs = 3  # You can adjust the number of epochs\nfor epoch in range(epochs):\n    for batch in train_dataloader:\n        # Extract inputs from the batch\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        token_type_ids = batch[\"token_type_ids\"]\n        labels = batch[\"labels\"]\n        numeric_values = batch[\"numeric_values\"]\n        numeric_values_scale = batch[\"numeric_values_scale\"]\n        #float_answer = batch[\"float_answer\"]\n        batch_size = input_ids.shape[0]\n        dummy_float_answers = torch.zeros(batch_size, dtype=torch.float32)\n\n        # Zero the gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            labels=labels,\n            numeric_values=numeric_values,\n            numeric_values_scale=numeric_values_scale,\n            float_answer=dummy_float_answers,\n            \n        )\n\n        # Compute loss and perform backward pass\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:36:55.918154Z","iopub.execute_input":"2023-08-10T22:36:55.918539Z","iopub.status.idle":"2023-08-10T22:38:30.161368Z","shell.execute_reply.started":"2023-08-10T22:36:55.918510Z","shell.execute_reply":"2023-08-10T22:38:30.159839Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Downloading pytorch_model.bin: 100%|██████████| 443M/443M [00:04<00:00, 93.4MB/s] \nSome weights of TapasForQuestionAnswering were not initialized from the model checkpoint at google/tapas-base and are newly initialized: ['aggregation_classifier.bias', 'column_output_weights', 'aggregation_classifier.weight', 'output_weights', 'column_output_bias', 'output_bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"output_dir = \"/kaggle/working/model\"  # Modify this path accordingly\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:38:43.600667Z","iopub.execute_input":"2023-08-10T22:38:43.601132Z","iopub.status.idle":"2023-08-10T22:38:44.486229Z","shell.execute_reply.started":"2023-08-10T22:38:43.601096Z","shell.execute_reply":"2023-08-10T22:38:44.485096Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/model/tokenizer_config.json',\n '/kaggle/working/model/special_tokens_map.json',\n '/kaggle/working/model/vocab.txt',\n '/kaggle/working/model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"2. Finetune for Approval table \n/kaggle/input/attaindb/dbo-candidate-174-live.1690703493.csv","metadata":{}},{"cell_type":"code","source":"table=pd.read_csv(\"/kaggle/input/attaindb/dbo-candidate-174-live.1690703493.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:40:10.990006Z","iopub.execute_input":"2023-08-10T22:40:10.991254Z","iopub.status.idle":"2023-08-10T22:40:11.007114Z","shell.execute_reply.started":"2023-08-10T22:40:10.991210Z","shell.execute_reply":"2023-08-10T22:40:11.005811Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"table.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:40:15.180703Z","iopub.execute_input":"2023-08-10T22:40:15.181872Z","iopub.status.idle":"2023-08-10T22:40:15.206231Z","shell.execute_reply.started":"2023-08-10T22:40:15.181830Z","shell.execute_reply":"2023-08-10T22:40:15.205307Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   id     created_at  candidate_code first_name last_name middle_name  \\\n0   1  1690395114858           233.0     Adepeu     Ajiba         Ola   \n1   2  1685772573008          3333.0       Wale       Ade         NaN   \n2   3  1690510078908          2333.0  Adepeluuu     Ajiii         Ola   \n3   4  1685773187634          5666.0   Blessing       Ojo         NaN   \n4   5  1685773298907          3444.0      Nancy       Ada       Ngozi   \n\n          full_name initials  gender  birth_date  ... home_address  \\\n0         Adepe Aji      A.O    Male  2000-01-02  ...     Iba, Oyo   \n1          Wale Ade       QA    Male  1985-04-16  ...     Abeokuta   \n2  Adepeluuuu Ajiii      A.A    Male  2000-01-01  ...  Ibadan, Oyo   \n3      Blessing Ojo       BO  Female  1989-12-14  ...   Benin City   \n4         Nancy Ada      NaN  Female  1991-09-18  ...        Enugu   \n\n                email legal_id_type legal_id_number stage_id created_by  \\\n0     adepe@gmail.com           NIN     54352525252        1          1   \n1   waleade@gmail.com           NaN               0        2          0   \n2       ade@gmail.com           NIN   5435352525252        1          1   \n3  blessing@gmail.com           NaN               0        3          0   \n4  ngoziada@gmail.com           NaN               0        2          0   \n\n   updated_at  updated_by  organization_id     Source  \n0         2.0           1                1   Linkedin  \n1         NaN           0                1   Job Page  \n2         2.0           1                1   Linkedin  \n3         NaN           0                1  Referrals  \n4         NaN           0                1     Indeed  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>created_at</th>\n      <th>candidate_code</th>\n      <th>first_name</th>\n      <th>last_name</th>\n      <th>middle_name</th>\n      <th>full_name</th>\n      <th>initials</th>\n      <th>gender</th>\n      <th>birth_date</th>\n      <th>...</th>\n      <th>home_address</th>\n      <th>email</th>\n      <th>legal_id_type</th>\n      <th>legal_id_number</th>\n      <th>stage_id</th>\n      <th>created_by</th>\n      <th>updated_at</th>\n      <th>updated_by</th>\n      <th>organization_id</th>\n      <th>Source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1690395114858</td>\n      <td>233.0</td>\n      <td>Adepeu</td>\n      <td>Ajiba</td>\n      <td>Ola</td>\n      <td>Adepe Aji</td>\n      <td>A.O</td>\n      <td>Male</td>\n      <td>2000-01-02</td>\n      <td>...</td>\n      <td>Iba, Oyo</td>\n      <td>adepe@gmail.com</td>\n      <td>NIN</td>\n      <td>54352525252</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Linkedin</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1685772573008</td>\n      <td>3333.0</td>\n      <td>Wale</td>\n      <td>Ade</td>\n      <td>NaN</td>\n      <td>Wale Ade</td>\n      <td>QA</td>\n      <td>Male</td>\n      <td>1985-04-16</td>\n      <td>...</td>\n      <td>Abeokuta</td>\n      <td>waleade@gmail.com</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Job Page</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1690510078908</td>\n      <td>2333.0</td>\n      <td>Adepeluuu</td>\n      <td>Ajiii</td>\n      <td>Ola</td>\n      <td>Adepeluuuu Ajiii</td>\n      <td>A.A</td>\n      <td>Male</td>\n      <td>2000-01-01</td>\n      <td>...</td>\n      <td>Ibadan, Oyo</td>\n      <td>ade@gmail.com</td>\n      <td>NIN</td>\n      <td>5435352525252</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Linkedin</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1685773187634</td>\n      <td>5666.0</td>\n      <td>Blessing</td>\n      <td>Ojo</td>\n      <td>NaN</td>\n      <td>Blessing Ojo</td>\n      <td>BO</td>\n      <td>Female</td>\n      <td>1989-12-14</td>\n      <td>...</td>\n      <td>Benin City</td>\n      <td>blessing@gmail.com</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Referrals</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1685773298907</td>\n      <td>3444.0</td>\n      <td>Nancy</td>\n      <td>Ada</td>\n      <td>Ngozi</td>\n      <td>Nancy Ada</td>\n      <td>NaN</td>\n      <td>Female</td>\n      <td>1991-09-18</td>\n      <td>...</td>\n      <td>Enugu</td>\n      <td>ngoziada@gmail.com</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Indeed</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Generate questions\nquestions = []\nanswer_coordinates = []\nanswer_text = []\n\nfor i, row in table.iterrows():\n    questions.append(f\"What is the full name for candidate {row['full_name']} (row {i + 1})?\")\n    answer_coordinates.append([(i, table.columns.get_loc(\"full_name\"))])\n    answer_text.append(str(table.iat[i, table.columns.get_loc(\"full_name\")]))\n    \n    questions.append(f\"What is the email for candidate {row['full_name']} (row {i + 1})?\")\n    answer_coordinates.append([(i, table.columns.get_loc(\"email\"))])\n    answer_text.append(str(table.iat[i, table.columns.get_loc(\"email\")]))","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:40:19.602585Z","iopub.execute_input":"2023-08-10T22:40:19.603826Z","iopub.status.idle":"2023-08-10T22:40:19.614549Z","shell.execute_reply.started":"2023-08-10T22:40:19.603781Z","shell.execute_reply":"2023-08-10T22:40:19.613449Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Tokenize the data\ntokenizer = TapasTokenizer.from_pretrained(\"/kaggle/working/model\")\ninputs = tokenizer(\n    table=table.astype(str),  # Convert table data to text-only\n    queries=questions,\n    answer_coordinates=answer_coordinates,\n    answer_text=answer_text,\n    padding= True,\n    return_tensors=\"pt\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:40:26.547861Z","iopub.execute_input":"2023-08-10T22:40:26.548329Z","iopub.status.idle":"2023-08-10T22:40:33.347356Z","shell.execute_reply.started":"2023-08-10T22:40:26.548295Z","shell.execute_reply":"2023-08-10T22:40:33.346067Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (873 > 512). Running this sequence through the model will result in indexing errors.\n","output_type":"stream"}]},{"cell_type":"code","source":"class TableDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, tokenizer):\n        self.inputs = inputs\n        self.tokenizer = tokenizer\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.inputs.items()}\n        return item\n\n    def __len__(self):\n        return len(self.inputs[\"input_ids\"])\n\n# Create the DataLoader\ntrain_dataset = TableDataset(inputs, tokenizer)\nbatch_size = 8  # You can adjust this based on your resources\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:40:44.263561Z","iopub.execute_input":"2023-08-10T22:40:44.264811Z","iopub.status.idle":"2023-08-10T22:40:44.276481Z","shell.execute_reply.started":"2023-08-10T22:40:44.264767Z","shell.execute_reply":"2023-08-10T22:40:44.275418Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from transformers import TapasConfig, TapasForQuestionAnswering, AdamW\n\n# Define the configuration\nconfig = TapasConfig(\n    num_aggregation_labels=4,\n    use_answer_as_supervision=True,\n    answer_loss_cutoff=0.664694,\n    cell_selection_preference=0.207951,\n    huber_loss_delta=0.121194,\n    init_cell_selection_weights_to_zero=True,\n    select_one_column=True,\n    allow_empty_column_selection=False,\n    temperature=0.0352513,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:40:50.338230Z","iopub.execute_input":"2023-08-10T22:40:50.338671Z","iopub.status.idle":"2023-08-10T22:40:50.345181Z","shell.execute_reply.started":"2023-08-10T22:40:50.338637Z","shell.execute_reply":"2023-08-10T22:40:50.344212Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = TapasForQuestionAnswering.from_pretrained(\"/kaggle/working/model\", config=config)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:41:00.773175Z","iopub.execute_input":"2023-08-10T22:41:00.773628Z","iopub.status.idle":"2023-08-10T22:41:01.892610Z","shell.execute_reply.started":"2023-08-10T22:41:00.773592Z","shell.execute_reply":"2023-08-10T22:41:01.891212Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Set up optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# Put the model in training mode\nmodel.train()\n\n# Training loop\nepochs = 3  # You can adjust the number of epochs\nfor epoch in range(epochs):\n    for batch in train_dataloader:\n        # Extract inputs from the batch\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        token_type_ids = batch[\"token_type_ids\"]\n        labels = batch[\"labels\"]\n        numeric_values = batch[\"numeric_values\"]\n        numeric_values_scale = batch[\"numeric_values_scale\"]\n        #float_answer = batch[\"float_answer\"]\n        batch_size = input_ids.shape[0]\n        dummy_float_answers = torch.zeros(batch_size, dtype=torch.float32)\n\n        # Zero the gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            labels=labels,\n            numeric_values=numeric_values,\n            numeric_values_scale=numeric_values_scale,\n            float_answer=dummy_float_answers,\n            \n        )\n\n        # Compute loss and perform backward pass\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T22:45:22.539885Z","iopub.execute_input":"2023-08-10T22:45:22.540820Z","iopub.status.idle":"2023-08-10T22:46:46.317225Z","shell.execute_reply.started":"2023-08-10T22:45:22.540763Z","shell.execute_reply":"2023-08-10T22:46:46.315934Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"output_dir = \"/kaggle/working/model\"  # Modify this path accordingly\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:19:29.320168Z","iopub.execute_input":"2023-08-10T23:19:29.320657Z","iopub.status.idle":"2023-08-10T23:19:30.273967Z","shell.execute_reply.started":"2023-08-10T23:19:29.320620Z","shell.execute_reply":"2023-08-10T23:19:30.272956Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/model/tokenizer_config.json',\n '/kaggle/working/model/special_tokens_map.json',\n '/kaggle/working/model/vocab.txt',\n '/kaggle/working/model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"For Employee paytypes ","metadata":{}},{"cell_type":"code","source":"table= pd.read_csv(\"/kaggle/input/attaindb/dbo-employee_paytypes-218-live.1690705274.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:19:34.104206Z","iopub.execute_input":"2023-08-10T23:19:34.105245Z","iopub.status.idle":"2023-08-10T23:19:34.118072Z","shell.execute_reply.started":"2023-08-10T23:19:34.105205Z","shell.execute_reply":"2023-08-10T23:19:34.117133Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"table.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:19:36.851010Z","iopub.execute_input":"2023-08-10T23:19:36.851444Z","iopub.status.idle":"2023-08-10T23:19:36.868817Z","shell.execute_reply.started":"2023-08-10T23:19:36.851410Z","shell.execute_reply":"2023-08-10T23:19:36.867899Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"   id     created_at  paytypes_id  employee_id  amount  status  start_date  \\\n0   1  1684317020263            4           87  500000  active         NaN   \n1   3  1684317931161            3           92       0  active  2023-05-17   \n2   5  1685207905335            5           91   40000  active  2023-06-05   \n3   6  1685975480538            3           93    7000  active  2023-05-17   \n\n     end_date    updated_at created_by updated_by  organization_id  \\\n0         NaN           NaN        NaN        NaN                1   \n1  2024-05-03           NaN      faruq      faruq                6   \n2  2023-06-05  1.685975e+12    Zulikif    Zulikif                1   \n3  2024-09-20  1.685976e+12    Zulikif    Zulikif                1   \n\n   pay_schedule_id  payroll_config_id  \n0                1                  2  \n1                0                  0  \n2                0                  0  \n3                0                  0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>created_at</th>\n      <th>paytypes_id</th>\n      <th>employee_id</th>\n      <th>amount</th>\n      <th>status</th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>updated_at</th>\n      <th>created_by</th>\n      <th>updated_by</th>\n      <th>organization_id</th>\n      <th>pay_schedule_id</th>\n      <th>payroll_config_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1684317020263</td>\n      <td>4</td>\n      <td>87</td>\n      <td>500000</td>\n      <td>active</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1684317931161</td>\n      <td>3</td>\n      <td>92</td>\n      <td>0</td>\n      <td>active</td>\n      <td>2023-05-17</td>\n      <td>2024-05-03</td>\n      <td>NaN</td>\n      <td>faruq</td>\n      <td>faruq</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>1685207905335</td>\n      <td>5</td>\n      <td>91</td>\n      <td>40000</td>\n      <td>active</td>\n      <td>2023-06-05</td>\n      <td>2023-06-05</td>\n      <td>1.685975e+12</td>\n      <td>Zulikif</td>\n      <td>Zulikif</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>1685975480538</td>\n      <td>3</td>\n      <td>93</td>\n      <td>7000</td>\n      <td>active</td>\n      <td>2023-05-17</td>\n      <td>2024-09-20</td>\n      <td>1.685976e+12</td>\n      <td>Zulikif</td>\n      <td>Zulikif</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Generate questions, answer coordinates, and answer text\nquestions = []\nanswer_coordinates = []\nanswer_text = []\n\n# Questions about the status of an employee paytype\nfor i, row in table.iterrows():\n    questions.append(f\"What is the status of employee {row['employee_id']}'s paytype?\")\n    answer_coordinates.append([(i, table.columns.get_loc('status'))])\n    answer_text.append(row['status'])\n\n# Questions about the amount\nfor i, row in table.iterrows():\n    questions.append(f\"What is the amount for employee {row['employee_id']}?\")\n    answer_coordinates.append([(i, table.columns.get_loc('amount'))])\n    answer_text.append(str(row['amount']))","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:19:43.042494Z","iopub.execute_input":"2023-08-10T23:19:43.042962Z","iopub.status.idle":"2023-08-10T23:19:43.052773Z","shell.execute_reply.started":"2023-08-10T23:19:43.042910Z","shell.execute_reply":"2023-08-10T23:19:43.051877Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"\ninputs = tokenizer(\n    table=table.astype(str),  # Convert table data to text-only\n    queries=questions,\n    answer_coordinates=answer_coordinates,\n    answer_text=answer_text,\n    padding= \"max_length\",\n    return_tensors=\"pt\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:19:51.323068Z","iopub.execute_input":"2023-08-10T23:19:51.323508Z","iopub.status.idle":"2023-08-10T23:19:51.601120Z","shell.execute_reply.started":"2023-08-10T23:19:51.323477Z","shell.execute_reply":"2023-08-10T23:19:51.600247Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass TableDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, tokenizer):\n        self.inputs = inputs\n        self.tokenizer = tokenizer\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.inputs.items()}\n        return item\n\n    def __len__(self):\n        return len(self.inputs[\"input_ids\"])\n\n# Create the DataLoader\ntrain_dataset = TableDataset(inputs, tokenizer)\nbatch_size = 8  # You can adjust this based on your resources\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:20:00.520113Z","iopub.execute_input":"2023-08-10T23:20:00.520678Z","iopub.status.idle":"2023-08-10T23:20:00.529647Z","shell.execute_reply.started":"2023-08-10T23:20:00.520626Z","shell.execute_reply":"2023-08-10T23:20:00.528753Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Define the configuration\nconfig = TapasConfig(\n    num_aggregation_labels=4,\n    use_answer_as_supervision=True,\n    answer_loss_cutoff=0.664694,\n    cell_selection_preference=0.207951,\n    huber_loss_delta=0.121194,\n    init_cell_selection_weights_to_zero=True,\n    select_one_column=True,\n    allow_empty_column_selection=False,\n    temperature=0.0352513,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:20:13.232265Z","iopub.execute_input":"2023-08-10T23:20:13.232744Z","iopub.status.idle":"2023-08-10T23:20:13.239730Z","shell.execute_reply.started":"2023-08-10T23:20:13.232707Z","shell.execute_reply":"2023-08-10T23:20:13.238758Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\nmodel = TapasForQuestionAnswering.from_pretrained(\"/kaggle/working/model\", config=config)\n\n# Set up optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:20:31.519586Z","iopub.execute_input":"2023-08-10T23:20:31.520638Z","iopub.status.idle":"2023-08-10T23:20:32.637109Z","shell.execute_reply.started":"2023-08-10T23:20:31.520596Z","shell.execute_reply":"2023-08-10T23:20:32.635916Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Put the model in training mode\nmodel.train()\n\n# Training loop\nepochs = 3  # You can adjust the number of epochs\nfor epoch in range(epochs):\n    for batch in train_dataloader:\n        # Extract inputs from the batch\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        token_type_ids = batch[\"token_type_ids\"]\n        labels = batch[\"labels\"]\n        numeric_values = batch[\"numeric_values\"]\n        numeric_values_scale = batch[\"numeric_values_scale\"]\n        #float_answer = batch[\"float_answer\"]\n        batch_size = input_ids.shape[0]\n        dummy_float_answers = torch.zeros(batch_size, dtype=torch.float32)\n\n        # Zero the gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            labels=labels,\n            numeric_values=numeric_values,\n            numeric_values_scale=numeric_values_scale,\n            float_answer=dummy_float_answers,\n            \n        )\n\n        # Compute loss and perform backward pass\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n\noutput_dir = \"/kaggle/working/model\"  # Modify this path accordingly\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:20:37.723328Z","iopub.execute_input":"2023-08-10T23:20:37.723776Z","iopub.status.idle":"2023-08-10T23:20:45.342099Z","shell.execute_reply.started":"2023-08-10T23:20:37.723734Z","shell.execute_reply":"2023-08-10T23:20:45.341206Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/model/tokenizer_config.json',\n '/kaggle/working/model/special_tokens_map.json',\n '/kaggle/working/model/vocab.txt',\n '/kaggle/working/model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"For employee Review Question ","metadata":{}},{"cell_type":"code","source":"table=pd.read_csv(\"/kaggle/input/attaindb/dbo-ep_review_question-270-live.1690705733.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:20:55.973538Z","iopub.execute_input":"2023-08-10T23:20:55.974101Z","iopub.status.idle":"2023-08-10T23:20:55.982952Z","shell.execute_reply.started":"2023-08-10T23:20:55.974059Z","shell.execute_reply":"2023-08-10T23:20:55.982011Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"table.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:21:09.906183Z","iopub.execute_input":"2023-08-10T23:21:09.906639Z","iopub.status.idle":"2023-08-10T23:21:09.919307Z","shell.execute_reply.started":"2023-08-10T23:21:09.906603Z","shell.execute_reply":"2023-08-10T23:21:09.918447Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"   id     created_at                            text response_type  review_id  \\\n0  12  1689435910841   How are you doing in the job?        rating         10   \n1  13  1689435948936   How are you doing in the job?        rating         11   \n2  14  1689435966827  How many courses did you take?        rating         11   \n3  15  1689740506227  How do you feel about your job          text         12   \n\n   organization_id  \n0                1  \n1                1  \n2                1  \n3                1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>created_at</th>\n      <th>text</th>\n      <th>response_type</th>\n      <th>review_id</th>\n      <th>organization_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12</td>\n      <td>1689435910841</td>\n      <td>How are you doing in the job?</td>\n      <td>rating</td>\n      <td>10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13</td>\n      <td>1689435948936</td>\n      <td>How are you doing in the job?</td>\n      <td>rating</td>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14</td>\n      <td>1689435966827</td>\n      <td>How many courses did you take?</td>\n      <td>rating</td>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>1689740506227</td>\n      <td>How do you feel about your job</td>\n      <td>text</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"questions = []\nanswer_coordinates = []\nanswer_text = []\n\nfor i, row in table.iterrows():\n    question_text = f\"What is the 'text' for review ID {row['review_id']}?\"\n    question_response_type = f\"What is the 'response_type' for review ID {row['review_id']}?\"\n    \n    questions.extend([question_text, question_response_type])\n    \n    answer_coordinates.extend([[(i, table.columns.get_loc('text'))], [(i, table.columns.get_loc('response_type'))]])\n    answer_text.extend([row['text'], row['response_type']])","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:21:17.819938Z","iopub.execute_input":"2023-08-10T23:21:17.820379Z","iopub.status.idle":"2023-08-10T23:21:17.828744Z","shell.execute_reply.started":"2023-08-10T23:21:17.820345Z","shell.execute_reply":"2023-08-10T23:21:17.827916Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Tokenize the data\ntokenizer = TapasTokenizer.from_pretrained(\"/kaggle/working/model\")\ninputs = tokenizer(\n    table=table.astype(str),  # Convert table data to text-only\n    queries=questions,\n    answer_coordinates=answer_coordinates,\n    answer_text=answer_text,\n    padding=\"max_length\",\n    return_tensors=\"pt\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:23:56.526530Z","iopub.execute_input":"2023-08-10T23:23:56.527077Z","iopub.status.idle":"2023-08-10T23:23:56.708496Z","shell.execute_reply.started":"2023-08-10T23:23:56.527035Z","shell.execute_reply":"2023-08-10T23:23:56.707387Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class TableDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, tokenizer):\n        self.inputs = inputs\n        self.tokenizer = tokenizer\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.inputs.items()}\n        return item\n\n    def __len__(self):\n        return len(self.inputs[\"input_ids\"])\n\n# Create the DataLoader\ntrain_dataset = TableDataset(inputs, tokenizer)\nbatch_size = 8  # You can adjust this based on your resources\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:24:16.562879Z","iopub.execute_input":"2023-08-10T23:24:16.563346Z","iopub.status.idle":"2023-08-10T23:24:16.575643Z","shell.execute_reply.started":"2023-08-10T23:24:16.563312Z","shell.execute_reply":"2023-08-10T23:24:16.574469Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# Define the configuration\nconfig = TapasConfig(\n    num_aggregation_labels=4,\n    use_answer_as_supervision=True,\n    answer_loss_cutoff=0.664694,\n    cell_selection_preference=0.207951,\n    huber_loss_delta=0.121194,\n    init_cell_selection_weights_to_zero=True,\n    select_one_column=True,\n    allow_empty_column_selection=False,\n    temperature=0.0352513,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:24:38.083159Z","iopub.execute_input":"2023-08-10T23:24:38.083626Z","iopub.status.idle":"2023-08-10T23:24:38.089904Z","shell.execute_reply.started":"2023-08-10T23:24:38.083590Z","shell.execute_reply":"2023-08-10T23:24:38.088971Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"model = TapasForQuestionAnswering.from_pretrained(\"/kaggle/working/model\", config=config)\n# Set up optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:26:06.795041Z","iopub.execute_input":"2023-08-10T23:26:06.795494Z","iopub.status.idle":"2023-08-10T23:26:07.936012Z","shell.execute_reply.started":"2023-08-10T23:26:06.795459Z","shell.execute_reply":"2023-08-10T23:26:07.934602Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Put the model in training mode\nmodel.train()\n\n# Training loop\nepochs = 3  # You can adjust the number of epochs\nfor epoch in range(epochs):\n    for batch in train_dataloader:\n        # Extract inputs from the batch\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        token_type_ids = batch[\"token_type_ids\"]\n        labels = batch[\"labels\"]\n        numeric_values = batch[\"numeric_values\"]\n        numeric_values_scale = batch[\"numeric_values_scale\"]\n        #float_answer = batch[\"float_answer\"]\n        batch_size = input_ids.shape[0]\n        dummy_float_answers = torch.zeros(batch_size, dtype=torch.float32)\n\n        # Zero the gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            labels=labels,\n            numeric_values=numeric_values,\n            numeric_values_scale=numeric_values_scale,\n            float_answer=dummy_float_answers,\n            \n        )\n\n        # Compute loss and perform backward pass\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n\noutput_dir = \"/kaggle/working/model\"  # Modify this path accordingly\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:26:29.438381Z","iopub.execute_input":"2023-08-10T23:26:29.438832Z","iopub.status.idle":"2023-08-10T23:26:36.898942Z","shell.execute_reply.started":"2023-08-10T23:26:29.438797Z","shell.execute_reply":"2023-08-10T23:26:36.898065Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/model/tokenizer_config.json',\n '/kaggle/working/model/special_tokens_map.json',\n '/kaggle/working/model/vocab.txt',\n '/kaggle/working/model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"markdown","source":"Fou User Onboarding ","metadata":{}},{"cell_type":"code","source":"table=pd.read_csv(\"/kaggle/input/attaindb/dbo-user_onboarding_task-184-live.1690887111.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:44:12.455336Z","iopub.execute_input":"2023-08-10T23:44:12.455841Z","iopub.status.idle":"2023-08-10T23:44:12.473306Z","shell.execute_reply.started":"2023-08-10T23:44:12.455802Z","shell.execute_reply":"2023-08-10T23:44:12.472420Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"table.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:44:31.555158Z","iopub.execute_input":"2023-08-10T23:44:31.555609Z","iopub.status.idle":"2023-08-10T23:44:31.568377Z","shell.execute_reply.started":"2023-08-10T23:44:31.555575Z","shell.execute_reply":"2023-08-10T23:44:31.567570Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"   id     created_at          task_name  description  sequence  \\\n0   1  1685789586041  user_registration          NaN         0   \n1   2  1685789632035   org_registration          NaN         0   \n2   3  1685789651204      app_selection          NaN         0   \n3   4  1685789659039                NaN          NaN         0   \n\n   organization_id  \n0                1  \n1                1  \n2                1  \n3                0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>created_at</th>\n      <th>task_name</th>\n      <th>description</th>\n      <th>sequence</th>\n      <th>organization_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1685789586041</td>\n      <td>user_registration</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1685789632035</td>\n      <td>org_registration</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1685789651204</td>\n      <td>app_selection</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1685789659039</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"questions = []\nanswer_coordinates = []\nanswer_text = []\n\nfor i, row in table.iterrows():\n    if row['task_name'] is not None:\n        question_task_name = f\"What is the 'task_name' for ID {row['id']}?\"\n        questions.append(question_task_name)\n        \n        answer_coordinates.append([(i, table.columns.get_loc('task_name'))])\n        answer_text.append(row['task_name'])","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:47:26.926032Z","iopub.execute_input":"2023-08-10T23:47:26.927072Z","iopub.status.idle":"2023-08-10T23:47:26.934910Z","shell.execute_reply.started":"2023-08-10T23:47:26.927026Z","shell.execute_reply":"2023-08-10T23:47:26.933977Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Tokenize the data\ntokenizer = TapasTokenizer.from_pretrained(\"/kaggle/working/model\")\ninputs = tokenizer(\n    table=table.astype(str),  # Convert table data to text-only\n    queries=questions,\n    answer_coordinates=answer_coordinates,\n    answer_text=answer_text,\n    padding=\"max_length\",\n    return_tensors=\"pt\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:48:16.398639Z","iopub.execute_input":"2023-08-10T23:48:16.399768Z","iopub.status.idle":"2023-08-10T23:48:16.516086Z","shell.execute_reply.started":"2023-08-10T23:48:16.399715Z","shell.execute_reply":"2023-08-10T23:48:16.514703Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"class TableDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, tokenizer):\n        self.inputs = inputs\n        self.tokenizer = tokenizer\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.inputs.items()}\n        return item\n\n    def __len__(self):\n        return len(self.inputs[\"input_ids\"])\n\n# Create the DataLoader\ntrain_dataset = TableDataset(inputs, tokenizer)\nbatch_size = 8  # You can adjust this based on your resources\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:48:45.689872Z","iopub.execute_input":"2023-08-10T23:48:45.691259Z","iopub.status.idle":"2023-08-10T23:48:45.703460Z","shell.execute_reply.started":"2023-08-10T23:48:45.691214Z","shell.execute_reply":"2023-08-10T23:48:45.702246Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# Define the configuration\nconfig = TapasConfig(\n    num_aggregation_labels=4,\n    use_answer_as_supervision=True,\n    answer_loss_cutoff=0.664694,\n    cell_selection_preference=0.207951,\n    huber_loss_delta=0.121194,\n    init_cell_selection_weights_to_zero=True,\n    select_one_column=True,\n    allow_empty_column_selection=False,\n    temperature=0.0352513,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:49:39.475189Z","iopub.execute_input":"2023-08-10T23:49:39.475689Z","iopub.status.idle":"2023-08-10T23:49:39.482830Z","shell.execute_reply.started":"2023-08-10T23:49:39.475648Z","shell.execute_reply":"2023-08-10T23:49:39.481573Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model = TapasForQuestionAnswering.from_pretrained(\"/kaggle/working/model\", config=config)\n# Set up optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:50:20.038191Z","iopub.execute_input":"2023-08-10T23:50:20.039455Z","iopub.status.idle":"2023-08-10T23:50:21.238659Z","shell.execute_reply.started":"2023-08-10T23:50:20.039407Z","shell.execute_reply":"2023-08-10T23:50:21.237323Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Put the model in training mode\nmodel.train()\n\n# Training loop\nepochs = 3  # You can adjust the number of epochs\nfor epoch in range(epochs):\n    for batch in train_dataloader:\n        # Extract inputs from the batch\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n        token_type_ids = batch[\"token_type_ids\"]\n        labels = batch[\"labels\"]\n        numeric_values = batch[\"numeric_values\"]\n        numeric_values_scale = batch[\"numeric_values_scale\"]\n        #float_answer = batch[\"float_answer\"]\n        batch_size = input_ids.shape[0]\n        dummy_float_answers = torch.zeros(batch_size, dtype=torch.float32)\n\n        # Zero the gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            labels=labels,\n            numeric_values=numeric_values,\n            numeric_values_scale=numeric_values_scale,\n            float_answer=dummy_float_answers,\n            \n        )\n\n        # Compute loss and perform backward pass\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n\noutput_dir = \"/kaggle/working/model\"  # Modify this path accordingly\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T23:50:46.609701Z","iopub.execute_input":"2023-08-10T23:50:46.610764Z","iopub.status.idle":"2023-08-10T23:50:50.502253Z","shell.execute_reply.started":"2023-08-10T23:50:46.610710Z","shell.execute_reply":"2023-08-10T23:50:50.501355Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/model/tokenizer_config.json',\n '/kaggle/working/model/special_tokens_map.json',\n '/kaggle/working/model/vocab.txt',\n '/kaggle/working/model/added_tokens.json')"},"metadata":{}}]}]}